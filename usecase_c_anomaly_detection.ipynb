{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947262d0-97ee-404f-bdd1-f225ffa22828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4fc94-9c53-4689-9112-51fc7527d152",
   "metadata": {},
   "source": [
    "# Anomaly detection\n",
    "\n",
    "This is \"use case c\" from the list of planned use cases:\n",
    "1. (a). **Trends monitoring**. User specifies log fields to monitor and specifies their min/max/alert levels. Tool makes prognosis and form summary for these log fields (and also for system load, e.g. number of messages per hour). The prognosis is based on previous dynamics, previous/future working days, holidays, and other events (like maintenance windows).\n",
    "1. (b). **Logs comparison**. User compares current logs with the previous ones (e.g. from previous release). User selects log fields to analyze. Tool highlights high-level differences, like number of messages, differences in prev/next hops, maybe different trends of field values.\n",
    "1. (c). **Anomalies in logs**. Tool tries to find messages, which donâ€™t look similar to most of others (for example, less than 1%). One more case: cluster log messages, if we see several types of them.\n",
    "1. (d). **Automatic fault detection**. Tool automatically finds and highlight failures, basing on HTTP codes and, probably, other fields.\n",
    "1. (e). **Failure patterns**. Using the data from automatic failure detection module, tool tries to find any pattern in failures, like occurring only on 5th time after connection setup, also it tries to find precursors to failure (certain messages or values, which appear before it happens)\n",
    "\n",
    "**TODO**:\n",
    "1. TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071a003-0a26-46fa-ae29-2b996e359946",
   "metadata": {},
   "source": [
    "## Service Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227e31da-0906-4e88-89a5-19ad6b7843ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logs(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        logs = json.load(f)\n",
    "    return logs\n",
    "\n",
    "def find_event_time_anomaly(logs_dict, ts_win_address, win_size_sec):\n",
    "    ts_vals = logs_dict\n",
    "    for hop in ts_win_address.split('.'):\n",
    "        new_ts_vals = []\n",
    "        for msg in ts_vals:\n",
    "            if hop not in msg:\n",
    "                print(f\"WARNING: didn't find \\\"{hop}\\\" in message {msg}\")\n",
    "            else:\n",
    "                new_ts_vals.append(msg[hop])\n",
    "        ts_vals = new_ts_vals\n",
    "\n",
    "    ts_vals = sorted([\n",
    "        datetime.datetime.strptime(ts, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        for ts in ts_vals\n",
    "    ])  # automatic ISO conversion with \"fromisoformat()\" is supported only from Python 3.11\n",
    "\n",
    "    print(ts_vals)\n",
    "    \n",
    "    idx_freq = max(win_size_sec//2, 1)\n",
    "    event_idx = pd.date_range(start=ts_vals[0], end=ts_vals[-1] + datetime.timedelta(seconds=1), freq=f'{idx_freq}s')\n",
    "    event_cnt = []\n",
    "    idx = 0\n",
    "    prev_time = None\n",
    "    for next_time in event_idx:\n",
    "        if prev_time is None:\n",
    "            prev_time = next_time\n",
    "            continue\n",
    "        cnt = 0\n",
    "        while idx < len(ts_vals) and ts_vals[idx] >= prev_time and ts_vals[idx] < next_time:\n",
    "            cnt += 1\n",
    "            idx += 1\n",
    "        event_cnt.append(cnt)\n",
    "        prev_time = next_time\n",
    "    ts_s = pd.Series(data=event_cnt, index=event_idx[:-1])\n",
    "    # ts_df = pd.DataFrame(data={'event_time_sec': ts_vals})\n",
    "    # event_s = ts_df.groupby('event_time_sec').size().sort_index()\n",
    "    # freqs = event_s.rolling(window=f'{win_size_sec}s', min_periods=0).sum()\n",
    "    freqs = ts_s.rolling(window=f'{win_size_sec}s', min_periods=0).sum()\n",
    "    print(freqs)\n",
    "\n",
    "    # Tukey's Fence\n",
    "    k = 3  # to be sure that value is enough \"far out\"\n",
    "    q1 = freqs.quantile(0.25)\n",
    "    q3 = freqs.quantile(0.75)\n",
    "    low_thr = q1 - k * (q3 - q1)\n",
    "    high_thr = q1 + k * (q3 - q1)\n",
    "\n",
    "    too_rare_events = freqs[freqs < low_thr].index.tolist()\n",
    "    # too_rare_events = freqs[freqs > low_thr].index.tolist()  # remove\n",
    "    too_frequent_events = freqs[freqs > high_thr].index.tolist()\n",
    "\n",
    "    return too_rare_events, too_frequent_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87746536-2ddf-4ba4-b5ca-9cfa6ff293ed",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1ce7f8-c39e-4973-8853-253e18a5bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_dict = load_logs('data/elastic_logs_example_01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1411e9d-f3bf-4548-bd00-d1f3f064f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2024, 1, 27, 21, 11, 9), datetime.datetime(2024, 1, 27, 21, 11, 14), datetime.datetime(2024, 1, 27, 21, 11, 25), datetime.datetime(2024, 1, 27, 21, 11, 25), datetime.datetime(2024, 1, 27, 21, 17, 36), datetime.datetime(2024, 1, 27, 21, 17, 36), datetime.datetime(2024, 1, 27, 21, 17, 36), datetime.datetime(2024, 1, 27, 21, 17, 36), datetime.datetime(2024, 1, 27, 21, 17, 36), datetime.datetime(2024, 1, 27, 21, 17, 36)]\n",
      "2024-01-27 21:11:09    1.0\n",
      "2024-01-27 21:11:10    1.0\n",
      "2024-01-27 21:11:11    1.0\n",
      "2024-01-27 21:11:12    0.0\n",
      "2024-01-27 21:11:13    0.0\n",
      "                      ... \n",
      "2024-01-27 21:17:32    0.0\n",
      "2024-01-27 21:17:33    0.0\n",
      "2024-01-27 21:17:34    0.0\n",
      "2024-01-27 21:17:35    0.0\n",
      "2024-01-27 21:17:36    6.0\n",
      "Freq: S, Length: 388, dtype: float64\n",
      "Anomaly found: too frequent messages in the following time frames:\n",
      "\t from 2024-01-27 21:11:09 to 2024-01-27 21:11:12\n",
      "\t from 2024-01-27 21:11:10 to 2024-01-27 21:11:13\n",
      "\t from 2024-01-27 21:11:11 to 2024-01-27 21:11:14\n",
      "\t from 2024-01-27 21:11:14 to 2024-01-27 21:11:17\n",
      "\t from 2024-01-27 21:11:15 to 2024-01-27 21:11:18\n",
      "\t from 2024-01-27 21:11:16 to 2024-01-27 21:11:19\n",
      "\t from 2024-01-27 21:11:25 to 2024-01-27 21:11:28\n",
      "\t from 2024-01-27 21:11:26 to 2024-01-27 21:11:29\n",
      "\t from 2024-01-27 21:11:27 to 2024-01-27 21:11:30\n",
      "\t from 2024-01-27 21:17:36 to 2024-01-27 21:17:39\n"
     ]
    }
   ],
   "source": [
    "win_size_sec = 3\n",
    "too_rare_list, too_freq_list = find_event_time_anomaly(logs_dict, 'event.ingested', win_size_sec)\n",
    "if len(too_rare_list) > 0:\n",
    "    print(\"Anomaly found: too rare messages in the following time frames:\")\n",
    "    for win_start in too_rare_list:\n",
    "        print(f\"\\t from {win_start} to {win_start + datetime.timedelta(seconds=win_size_sec)}\")\n",
    "if len(too_freq_list) > 0:\n",
    "    print(\"Anomaly found: too frequent messages in the following time frames:\")\n",
    "    for win_start in too_freq_list:\n",
    "        print(f\"\\t from {win_start} to {win_start + datetime.timedelta(seconds=win_size_sec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe2cd5-d4f6-43a1-899a-4f9da0f76643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
