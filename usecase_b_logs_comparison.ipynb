{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cafba99-0e9b-449c-bb77-f0678d62af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a6564-7470-4648-97ae-0c92b269f539",
   "metadata": {},
   "source": [
    "# Logs comparison\n",
    "\n",
    "This is \"use case b\" from the list of planned use cases:\n",
    "1. (a). **Trends monitoring**. User specifies log fields to monitor and specifies their min/max/alert levels. Tool makes prognosis and form summary for these log fields (and also for system load, e.g. number of messages per hour). The prognosis is based on previous dynamics, previous/future working days, holidays, and other events (like maintenance windows).\n",
    "1. (b). **Logs comparison**. User compares current logs with the previous ones (e.g. from previous release). User selects log fields to analyze. Tool highlights high-level differences, like number of messages, differences in prev/next hops, maybe different trends of field values.\n",
    "1. (c). **Anomalies in logs**. Tool tries to find messages, which donâ€™t look similar to most of others (for example, less than 1%). One more case: cluster log messages, if we see several types of them.\n",
    "1. (d). **Automatic fault detection**. Tool automatically finds and highlight failures, basing on HTTP codes and, probably, other fields.\n",
    "1. (e). **Failure patterns**. Using the data from automatic failure detection module, tool tries to find any pattern in failures, like occurring only on 5th time after connection setup, also it tries to find precursors to failure (certain messages or values, which appear before it happens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3ea15-4cf1-4422-bad4-4e4f21b77fdf",
   "metadata": {},
   "source": [
    "## Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c0265a-2697-40a0-9391-10ff71ea854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FieldBaseType = enum.Enum('FieldBaseType', 'float integer categorical date string')\n",
    "\n",
    "class FieldType_General:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        if not isinstance(data, np.ndarray) or len(data.shape) != 1:\n",
    "            raise ValueError(f\"Expected 1-d numpy array, got: {type(data)}\")\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "class IntOrFloatMixin:\n",
    "\n",
    "    def find_big_differences(self, other_field):\n",
    "        BIG_DIFF_THR = 2  # We suppose that big diffs shold be greater than BIG_DIFF_THR*diff.mean()\n",
    "        RARE_DIFF_THR = 0.1  # We suppose that rare diffs should occur less than RARE_DIFF_THR*len(data)\n",
    "        MAX_THR_CHANGE_ITERS = 10  # No more than 10 iterations to find optimal threshold\n",
    "\n",
    "        other_data = other_field.data\n",
    "        if len(self.data) != len(other_data):\n",
    "            raise VelueError(f\"Lengths are not equal: {len(self.data)} and {len(other_data)}\")\n",
    "        diff = np.abs(self.data - other_data)\n",
    "        if np.isclose(diff.mean(), 0) or diff.max() <= BIG_DIFF_THR*diff.mean():\n",
    "            return np.array([], dtype=int)\n",
    "        diff_vals = np.unique(diff)\n",
    "        if len(diff_vals) < 2:\n",
    "            return np.array([], dtype=int)\n",
    "        biggest_thr = diff_vals[-2]  # one value before the maximum\n",
    "\n",
    "        big_thr = BIG_DIFF_THR*diff.mean()\n",
    "        if big_thr >= biggest_thr:\n",
    "            return np.array([], dtype=int)\n",
    "        found = False\n",
    "        for thr in np.linspace(big_thr, biggest_thr, num=MAX_THR_CHANGE_ITERS):\n",
    "            if len(np.where(diff > thr)) < RARE_DIFF_THR*len(diff):\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            times = np.argwhere(diff > thr)  # thr is still defined after loop\n",
    "        else:\n",
    "            times = np.array([], dtype=int)\n",
    "        return times\n",
    "\n",
    "\n",
    "class FieldType_Float(FieldType_General, IntOrFloatMixin):\n",
    "    BASE_TYPE = FieldBaseType.float\n",
    "\n",
    "\n",
    "class FieldType_Int(FieldType_General, IntOrFloatMixin):\n",
    "    BASE_TYPE = FieldBaseType.integer\n",
    "\n",
    "\n",
    "class FieldType_Cat(FieldType_General):\n",
    "    BASE_TYPE = FieldBaseType.categorical\n",
    "\n",
    "    def compare_categories(self, other_field):\n",
    "        other_data = other_field.data\n",
    "        # TODO: implementation is missing\n",
    "\n",
    "\n",
    "class FieldType_Date(FieldType_General):\n",
    "    BASE_TYPE = FieldBaseType.date\n",
    "\n",
    "    def __init__(self, data):\n",
    "        time_data = np.vectorize(lambda t: t.timestamp())(data)\n",
    "        super().__init__(time_data)\n",
    "\n",
    "\n",
    "class FieldType_Str(FieldType_General):\n",
    "    BASE_TYPE = FieldBaseType.string\n",
    "\n",
    "\n",
    "class FieldType_Resource(FieldType_Float):\n",
    "\n",
    "    def __init__(self, data, low_val, high_val, low_warn_level, high_warn_level):\n",
    "        super().__init__(data)\n",
    "        self.low_val = low_val\n",
    "        self.high_val = high_val\n",
    "        self.low_warn_level = low_warn_level\n",
    "        self.high_warn_level = high_warn_level\n",
    "\n",
    "\n",
    "class FieldType_CPUUtilization(FieldType_Resource):\n",
    "\n",
    "    def __init__(self, data, high_warn_level):\n",
    "        super().__init__(data, 0, 100, None, high_warn_level)\n",
    "\n",
    "\n",
    "class FieldType_RAMUtilization(FieldType_Resource):\n",
    "\n",
    "    def __init__(self, data, low_warn_level, high_warn_level):\n",
    "        super().__init__(data, 0, 100, low_warn_level, high_warn_level)\n",
    "\n",
    "\n",
    "def create_field_object(field_s, name, verbose=True):\n",
    "    obj = None\n",
    "    if obj is None:\n",
    "        if np.issubdtype(field_s.dtype, np.floating):\n",
    "            obj = FieldType_Float(field_s.values)\n",
    "        elif np.issubdtype(field_s.dtype, np.integer):\n",
    "            # TODO: may be categorical?\n",
    "            obj = FieldType_Int(field_s.values)\n",
    "    if obj is None:\n",
    "        # here we assume, that it is string, but it also can be categorical\n",
    "        try:\n",
    "            date_s = field_s.apply(dateutil.parser.parse)\n",
    "            obj = FieldType_Date(date_s.values)\n",
    "        except:\n",
    "            pass\n",
    "    if obj is None:\n",
    "        try:\n",
    "            float_s = field_s.apply(float)\n",
    "            try:\n",
    "                int_s = float_s.apply(int)\n",
    "                obj = FieldType_Int(int_s.values)\n",
    "            except:\n",
    "                obj = FieldType_Float(float_s.values)\n",
    "        except:\n",
    "            pass\n",
    "    if obj is None:\n",
    "        if field_s.nunique() < 0.9*len(field_s):\n",
    "            obj = FieldType_Cat(field_s.values)\n",
    "        else:\n",
    "            obj = FieldType_Str(field_s.values)\n",
    "    if verbose:\n",
    "        print(f\"{name}: autodetected type is {obj.BASE_TYPE}\")\n",
    "    return obj\n",
    "\n",
    "\n",
    "def align_base_field_types(field1, field2):\n",
    "    # TODO: implementation is missing\n",
    "    return field1, field2\n",
    "\n",
    "\n",
    "def compare_fields(field1: FieldType_General, field2: FieldType_General):\n",
    "    field1, field2 = align_base_field_types(field1, field2)\n",
    "    comparison_res = {}\n",
    "    if issubclass(type(field1), IntOrFloatMixin):\n",
    "        comparison_res['big_difference_idxs'] = field1.find_big_differences(field2)\n",
    "    return comparison_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc8e9fb-90fb-4e44-a905-60c7a0296ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@timestamp: autodetected type is FieldBaseType.string\n",
      "Class: autodetected type is FieldBaseType.categorical\n",
      "Class.keyword: autodetected type is FieldBaseType.categorical\n",
      "Device: autodetected type is FieldBaseType.categorical\n",
      "Level: autodetected type is FieldBaseType.categorical\n",
      "Line: autodetected type is FieldBaseType.integer\n",
      "Message: autodetected type is FieldBaseType.string\n",
      "Method: autodetected type is FieldBaseType.categorical\n",
      "Pod: autodetected type is FieldBaseType.categorical\n",
      "Service: autodetected type is FieldBaseType.categorical\n",
      "Subscriber: autodetected type is FieldBaseType.categorical\n",
      "Thread: autodetected type is FieldBaseType.categorical\n",
      "_id: autodetected type is FieldBaseType.string\n",
      "_index: autodetected type is FieldBaseType.categorical\n",
      "_score: autodetected type is FieldBaseType.categorical\n",
      "_type: autodetected type is FieldBaseType.categorical\n",
      "@timestamp: autodetected type is FieldBaseType.string\n",
      "Class: autodetected type is FieldBaseType.categorical\n",
      "Class.keyword: autodetected type is FieldBaseType.categorical\n",
      "Device: autodetected type is FieldBaseType.categorical\n",
      "Level: autodetected type is FieldBaseType.categorical\n",
      "Line: autodetected type is FieldBaseType.integer\n",
      "Message: autodetected type is FieldBaseType.string\n",
      "Method: autodetected type is FieldBaseType.categorical\n",
      "Pod: autodetected type is FieldBaseType.categorical\n",
      "Service: autodetected type is FieldBaseType.categorical\n",
      "Subscriber: autodetected type is FieldBaseType.categorical\n",
      "Thread: autodetected type is FieldBaseType.categorical\n",
      "_id: autodetected type is FieldBaseType.string\n",
      "_index: autodetected type is FieldBaseType.categorical\n",
      "_score: autodetected type is FieldBaseType.categorical\n",
      "_type: autodetected type is FieldBaseType.categorical\n",
      "{'big_difference_idxs': array([], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "logs1_df = pd.read_csv('data/chatbroker.csv')\n",
    "logs2_df = pd.read_csv('data/smsbroker.csv')\n",
    "\n",
    "fields1 = {col: create_field_object(logs1_df[col], col, verbose=True) for col in logs1_df.columns.tolist()}\n",
    "fields2 = {col: create_field_object(logs1_df[col], col, verbose=True) for col in logs2_df.columns.tolist()}\n",
    "\n",
    "res = compare_fields(fields1['Line'], fields2['Line'])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f940ef-a9cb-4b3f-8a74-917cfb15b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field by field comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1110a4-262c-4186-914a-290961729cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message statistics comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
